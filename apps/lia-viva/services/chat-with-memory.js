// ======================================================================
// üìå LIA MEMORY ENGINE ‚Äì Mem√≥ria Permanente com Supabase + Embeddings
// ======================================================================

import OpenAI from "openai";
import { createClient } from "@supabase/supabase-js";
import dotenv from "dotenv";
import fs from "fs";
import path from "path";

dotenv.config();

// ----------------------------------------------------------------------
// üìù LOG FILE
// ----------------------------------------------------------------------
const LOG_FILE = path.join(process.cwd(), "logs", "memory-debug.log");
if (!fs.existsSync(path.dirname(LOG_FILE))) {
    fs.mkdirSync(path.dirname(LOG_FILE), { recursive: true });
}

function logToFile(message) {
    const timestamp = new Date().toISOString();
    fs.appendFileSync(LOG_FILE, `[${timestamp}] ${message}\n`);
    console.log(message); // Also log to console
}

// ----------------------------------------------------------------------
// üîë SUPABASE
// ----------------------------------------------------------------------
const supabase = createClient(
    process.env.SUPABASE_URL,
    process.env.SUPABASE_SERVICE_KEY
);

// ----------------------------------------------------------------------
// üîë OPENAI
// ----------------------------------------------------------------------
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// ----------------------------------------------------------------------
// üß† Regras da Mem√≥ria
// ----------------------------------------------------------------------
//
// LIA s√≥ grava mem√≥rias quando:
// 1) S√£o informa√ß√µes est√°veis (nome, empresa, prefer√™ncias, projetos etc.)
// 2) S√£o √∫teis no futuro
// 3) N√£o s√£o tempor√°rias ("estou com fome", "estou no carro", etc.)
// ----------------------------------------------------------------------

const MEMORY_PROMPT = `
Voc√™ √© respons√°vel por identificar informa√ß√µes importantes que devem ser salvas
como mem√≥rias permanentes.

Extraia *apenas* mem√≥rias √∫teis para conversas futuras, como:

- Nome da pessoa
- Nome da empresa
- Prefer√™ncias
- Objetivos
- Projetos em andamento
- Dados que ser√£o √∫teis depois

N√ÉO salve:
- Emo√ß√µes moment√¢neas
- Situa√ß√µes tempor√°rias
- Reclama√ß√µes incidentais
- Frases soltas sem valor futuro

Retorne em formato JSON:
{
  "should_write_memory": boolean,
  "memory_to_write": string
}
`;

// ----------------------------------------------------------------------
// üß† Fun√ß√£o: Extrair mem√≥ria da fala do usu√°rio
// ----------------------------------------------------------------------
async function extractMemory(text) {
    const response = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        max_tokens: 200,
        messages: [
            { role: "system", content: MEMORY_PROMPT },
            { role: "user", content: text }
        ]
    });

    try {
        return JSON.parse(response.choices[0].message.content);
    } catch (err) {
        console.error("Erro ao interpretar mem√≥ria:", err);
        return { should_write_memory: false };
    }
}

// ----------------------------------------------------------------------
// üß† Fun√ß√£o: Classificar tipo de mem√≥ria
// ----------------------------------------------------------------------
async function classifyMemoryType(memoryText) {
    const response = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        max_tokens: 50,
        messages: [
            {
                role: "system",
                content: `Classifique a mem√≥ria em UMA categoria: personal, family, preference, business, company, address, reminder, misc.
Responda APENAS com a categoria.`
            },
            { role: "user", content: memoryText }
        ]
    });

    const type = response.choices[0].message.content.trim().toLowerCase();
    const validTypes = ['personal', 'family', 'preference', 'business', 'company', 'address', 'reminder', 'misc'];

    return validTypes.includes(type) ? type : 'misc';
}

// ----------------------------------------------------------------------
// üß† Fun√ß√£o: Salvar mem√≥ria no Supabase
// ----------------------------------------------------------------------
async function saveMemory(userId, memoryText, memoryType = 'misc', rawInput = '') {
    return supabase.from("memories").insert({
        user_id: userId,
        type: memoryType,
        content: memoryText,
        raw_input: rawInput,
        importance: 1
    });
}

// ----------------------------------------------------------------------
// üß† Fun√ß√£o: Retornar mem√≥rias existentes
// ----------------------------------------------------------------------
async function loadMemories(userId) {
    const { data } = await supabase
        .from("memories")
        .select("type, content, importance")
        .eq("user_id", userId)
        .order("importance", { ascending: false })
        .order("updated_at", { ascending: false })
        .limit(50);

    return data?.map(m => `[${m.type}] ${m.content}`) || [];
}

// ----------------------------------------------------------------------
// üß† Fun√ß√£o principal usada pelo realtime.js
// ----------------------------------------------------------------------
export async function runChatWithMemory(conversationId, text, history = []) {
    const userId = "00000000-0000-0000-0000-000000000001"; // DEV FIXO

    try {
        logToFile("üß† === INICIANDO CHAT COM MEM√ìRIA ===");
        logToFile(`   ConversationID: ${conversationId}`);
        logToFile(`   UserID: ${userId}`);
        logToFile(`   Texto: ${text}`);

        // 1) Carregar mem√≥rias permanentes
        logToFile("üìö Carregando mem√≥rias...");
        const memories = await loadMemories(userId);
        logToFile(`   ${memories.length} mem√≥rias carregadas`);
        if (memories.length > 0) {
            memories.forEach((m, i) => logToFile(`     ${i + 1}. ${m}`));
        }

        // 2) Extrair poss√≠vel mem√≥ria do texto novo
        logToFile("üîç Detectando informa√ß√µes importantes...");
        const extracted = await extractMemory(text);
        logToFile(`   Resultado detec√ß√£o: ${JSON.stringify(extracted)}`);

        if (extracted.should_write_memory) {
            logToFile(`üß† Nova mem√≥ria: ${extracted.memory_to_write}`);

            // Classificar tipo de mem√≥ria
            const memoryType = await classifyMemoryType(extracted.memory_to_write);
            logToFile(`   Tipo: ${memoryType}`);

            const saveResult = await saveMemory(userId, extracted.memory_to_write, memoryType, text);
            logToFile(`   Salvo no Supabase: ${JSON.stringify(saveResult)}`);
        }

        // 3) Criar contexto para resposta
        const contextBlock = memories.length
            ? `Mem√≥rias relevantes do usu√°rio:\n- ${memories.join("\n- ")}`
            : "Sem mem√≥rias permanentes registradas.";

        logToFile("ü§ñ Chamando GPT com contexto e ferramentas...");

        // üî• ADICIONAR FERRAMENTAS DE BUSCA
        const tools = [
            {
                type: "function",
                function: {
                    name: "buscarNaWeb",
                    description: "Busca informa√ß√µes atualizadas na web usando Google Custom Search. Use SEMPRE para: cota√ß√µes de moedas/crypto, clima/tempo, not√≠cias recentes, informa√ß√µes em tempo real, eventos atuais, ou qualquer dado que mude frequentemente.",
                    parameters: {
                        type: "object",
                        properties: {
                            query: {
                                type: "string",
                                description: "Termo de busca em portugu√™s. Exemplo: 'cota√ß√£o euro real hoje' ou 'clima em Lisboa'"
                            }
                        },
                        required: ["query"]
                    }
                }
            }
        ];

        const response = await openai.chat.completions.create({
            model: "gpt-4o-mini",
            max_tokens: 400,
            messages: [
                {
                    role: "system",
                    content:
                        "Voc√™ √© a LIA da Luminnus. Seja natural, humana, direta e profissional. SEMPRE use a ferramenta buscarNaWeb quando o usu√°rio perguntar sobre informa√ß√µes atualizadas, cota√ß√µes, not√≠cias, clima, ou qualquer dado em tempo real."
                },
                {
                    role: "system",
                    content: contextBlock
                },
                ...history,
                { role: "user", content: text }
            ],
            tools: tools,
            tool_choice: "auto"
        });

        const message = response.choices[0].message;

        // üî• PROCESSAR TOOL CALLS
        if (message.tool_calls && message.tool_calls.length > 0) {
            logToFile(`üîß Tool call detectado: ${message.tool_calls[0].function.name}`);

            const toolCall = message.tool_calls[0];
            const functionName = toolCall.function.name;
            const functionArgs = JSON.parse(toolCall.function.arguments);

            logToFile(`   Argumentos: ${JSON.stringify(functionArgs)}`);

            // Executar a fun√ß√£o
            let functionResult = "";
            if (functionName === "buscarNaWeb") {
                // Importar dinamicamente para evitar problemas circulares
                const { buscarNaWeb } = await import("../tools/search.js");
                functionResult = await buscarNaWeb(functionArgs.query);
                logToFile(`   Resultado busca: ${functionResult.substring(0, 100)}...`);
            }

            // Chamar GPT novamente com o resultado da fun√ß√£o
            logToFile("üîÑ Chamando GPT com resultado da ferramenta...");
            const secondResponse = await openai.chat.completions.create({
                model: "gpt-4o-mini",
                max_tokens: 400,
                messages: [
                    {
                        role: "system",
                        content: "Voc√™ √© a LIA da Luminnus. Seja natural, humana, direta e profissional."
                    },
                    {
                        role: "system",
                        content: contextBlock
                    },
                    ...history,
                    { role: "user", content: text },
                    message, // Mensagem original com tool_call
                    {
                        role: "tool",
                        tool_call_id: toolCall.id,
                        content: functionResult
                    }
                ]
            });

            const finalText = secondResponse.choices[0].message.content;
            logToFile(`‚úÖ Resposta final gerada: ${finalText.substring(0, 50)}...`);
            return finalText;
        }

        // Sem tool calls, retornar resposta direta
        const responseText = message.content;
        logToFile(`‚úÖ Resposta gerada: ${responseText.substring(0, 50)}...`);

        return responseText;

    } catch (error) {
        logToFile("‚ùå ERRO CR√çTICO em runChatWithMemory:");
        logToFile(`   Mensagem: ${error.message}`);
        logToFile(`   Stack: ${error.stack}`);
        return "Desculpe, ocorreu um erro ao processar sua mensagem.";
    }
}
