// ======================================================================
// üéØ ORQUESTRADOR MULTIMODAL v2.0 - Gemini as Core Brain
// ======================================================================
// Gemini 2.0 Flash = C√©rebro, Olhos, M√£os e Voz
// OpenAI (Whisper/TTS) = Interfaces Perif√©ricas de √Åudio
// ======================================================================

import { GoogleGenerativeAI } from '@google/generative-ai';
import { runGemini } from '../assistants/gemini.js';
import { LIA_FULL_PERSONALITY } from '../personality/lia-personality.js';
import OpenAI from 'openai';

// ======================================================================
// CONFIGURA√á√ÉO
// ======================================================================

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// ======================================================================
// FUN√á√ïES DE DECIS√ÉO
// ======================================================================

/**
 * Decide qual modelo usar baseado no input do usu√°rio
 */
function decidirModelo(input) {
  const { hasImage, hasDocument, requestType } = input;

  // v2.0: Gemini assume todos os pap√©is inteligentes
  if (hasImage || hasDocument) {
    return { model: 'gemini-vision', reason: 'An√°lise multimodal nativa' };
  }

  if (requestType === 'chart' || requestType === 'table') {
    return { model: 'gemini-visual', reason: 'Gera√ß√£o estruturada' };
  }

  if (requestType === 'image-generation') {
    return { model: 'gemini-imagen', reason: 'Gera√ß√£o visual' };
  }

  return { model: 'gemini-brain', reason: 'C√©rebro LIA (Gemini 2.0 Flash)' };
}

/**
 * Detecta tipo de requisi√ß√£o automaticamente
 */
function detectarTipoRequisicao(message) {
  const lower = message.toLowerCase();

  // Gr√°ficos
  if (lower.match(/gr√°fico|chart|graph|plot|visualiz/)) {
    return 'chart';
  }

  // Tabelas
  if (lower.match(/tabela|table|planilha|spreadsheet/)) {
    return 'table';
  }

  // Gera√ß√£o de imagem
  if (lower.match(/crie uma imagem|gere uma imagem|desenhe|ilustr/)) {
    return 'image-generation';
  }

  // C√≥digo
  if (lower.match(/crie (um|uma|o) c√≥digo|gere c√≥digo|fun√ß√£o|class|def /)) {
    return 'code';
  }

  // Documento
  if (lower.match(/crie (um|uma) documento|gere relat√≥rio|monte report/)) {
    return 'document';
  }

  return null;
}

// ======================================================================
// PROCESSAMENTO MULTIMODAL
// ======================================================================

/**
 * Processa requisi√ß√£o multimodal completa
 */
async function processarRequisicaoMultimodal({
  message,
  images = [],
  documents = [],
  conversationId,
  personality = 'viva',
}) {
  try {
    console.log('üéØ Orquestrador Multimodal ativado');

    // 1. Detectar tipo de requisi√ß√£o
    const requestType = detectarTipoRequisicao(message);

    // 2. Decidir qual modelo usar
    const decision = decidirModelo({
      message,
      hasImage: images.length > 0,
      hasDocument: documents.length > 0,
      requestType,
    });

    console.log(`‚úÖ Decis√£o: ${decision.model} (${decision.reason})`);

    // 3. Processar conforme modelo escolhido
    let response;

    switch (decision.model) {
      case 'gemini-vision':
        response = await processarComGeminiVision({
          message,
          images,
          documents,
        });
        break;

      case 'gemini-visual-generation':
        response = await processarGeracaoVisual({
          message,
          requestType,
        });
        break;

      case 'gemini-imagen':
        response = await processarGeracaoImagem({
          message,
        });
        break;

      case 'gemini-brain':
      default:
        response = await processarComGeminiBrain({
          message,
          conversationId,
          personality,
        });
        break;
    }

    // 4. Adicionar metadados
    response.metadata = {
      modelUsed: decision.model,
      reason: decision.reason,
      requestType,
      timestamp: Date.now(),
    };

    return response;

  } catch (error) {
    console.error('‚ùå Erro no orquestrador multimodal:', error);
    throw error;
  }
}

// ======================================================================
// PROCESSADORES ESPEC√çFICOS
// ======================================================================

/**
 * Processa com Gemini Brain (Substitui GPT-4o Mini)
 */
async function processarComGeminiBrain({ message, conversationId, personality }) {
  console.log('üß† Processando com Gemini 2.0 Flash (Brain)...');

  const memories = await loadMemories();
  const context = {
    messages: memories.map(m => ({ role: 'user', content: `Lembrete: ${m.content}` })),
    functions: getFunctions(),
    conversationId
  };

  const result = await runGemini(message, context);

  if (result.function_call) {
    await processFunctionCall(result.function_call);
  }

  return {
    mode: 'text',
    contentType: 'text',
    content: result.text,
  };
}

/**
 * Processa com Gemini Vision (an√°lise de imagens)
 */
async function processarComGeminiVision({ message, images, documents }) {
  console.log('üëÅÔ∏è Processando com Gemini Vision...');

  const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

  // Preparar partes (texto + imagens)
  const parts: any[] = [{ text: message }];

  // Adicionar imagens
  for (const imageData of images) {
    parts.push({
      inlineData: {
        mimeType: imageData.mimeType || 'image/jpeg',
        data: imageData.base64,
      },
    });
  }

  // Gerar conte√∫do
  const result = await model.generateContent(parts);
  const response = await result.response;
  const text = response.text();

  return {
    mode: 'multimodal',
    contentType: 'analysis',
    content: text,
  };
}

/**
 * Processa gera√ß√£o visual (gr√°ficos, tabelas)
 */
async function processarGeracaoVisual({ message, requestType }) {
  console.log('üìä Processando gera√ß√£o visual com Gemini...');

  // Usar Gemini para extrair dados estruturados
  const systemPrompt = `Voc√™ √© um assistente que extrai dados estruturados para gr√°ficos e tabelas.
Retorne APENAS um JSON v√°lido com title, labels, values (para gr√°fico) ou headers/rows (para tabela). Sem markdown.`;

  const result = await runGemini(message, {
    messages: [{ role: 'system', content: systemPrompt } as any],
    temperature: 0.2
  });

  try {
    const jsonStr = result.text.replace(/```json\n?|\n?```/g, '').trim();
    const data = JSON.parse(jsonStr);

    return {
      mode: 'multimodal',
      contentType: requestType,
      content: data,
    };
  } catch (err) {
    console.error('‚ùå Erro ao parsear JSON visual:', err);
    throw err;
  }
}

/**
 * Processa gera√ß√£o de imagem
 */
async function processarGeracaoImagem({ message }) {
  console.log('üé® Processando gera√ß√£o de imagem...');

  // Usar DALL-E 3 para imagens simples
  const response = await openai.images.generate({
    model: 'dall-e-3',
    prompt: message,
    n: 1,
    size: '1024x1024',
    quality: 'standard',
  });

  return {
    mode: 'multimodal',
    contentType: 'image',
    content: {
      url: response.data[0].url,
      prompt: message,
    },
  };
}

// ======================================================================
// HELPERS
// ======================================================================

function getPersonalityPrompt(personality) {
  const prompts = {
    clara: 'Voc√™ √© LIA (LUMINNUS AI), uma assistente clara, objetiva e precisa.',
    viva: 'Voc√™ √© LIA (LUMINNUS AI), uma assistente energ√©tica, criativa e envolvente.',
    firme: 'Voc√™ √© LIA (LUMINNUS AI), uma assistente assertiva, direta e profissional.',
  };
  return prompts[personality] || prompts.viva;
}

function getFunctions() {
  return [
    {
      name: 'saveMemory',
      description: 'Salva uma informa√ß√£o importante na mem√≥ria do usu√°rio.',
      parameters: {
        type: 'object',
        properties: {
          content: { type: 'string', description: 'O conte√∫do a ser salvo' },
          category: {
            type: 'string',
            enum: ['personal', 'work', 'preferences', 'general'],
            description: 'Categoria da mem√≥ria',
          },
        },
        required: ['content'],
      },
    },
  ];
}

async function processFunctionCall(functionCall: any) {
  const { name, arguments: args } = functionCall;
  const params = JSON.parse(args);

  if (name === 'saveMemory') {
    const { saveMemory } = await import('./memoryService.js');
    await saveMemory(params.content, params.category || 'general');
    console.log('üíæ Mem√≥ria salva:', params.content);
  }
}

async function loadMemories() {
  try {
    const { getMemories } = await import('./memoryService.js');
    return await getMemories();
  } catch {
    return [];
  }
}

// ======================================================================
// EXPORTS
// ======================================================================

export {
  processarRequisicaoMultimodal,
  decidirModelo,
  detectarTipoRequisicao,
};
